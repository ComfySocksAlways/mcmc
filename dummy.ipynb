{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "from numba import *\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "# Device Properties to get execution config\n",
    "# Get the current device\n",
    "device = cuda.get_current_device()\n",
    "\n",
    "# Access device properties\n",
    "warp_size = device.WARP_SIZE\n",
    "multi_processor_count = device.MULTIPROCESSOR_COUNT\n",
    "\n",
    "# print(warp_size)\n",
    "# print(multi_processor_count)\n",
    "tpb = warp_size                     # threads per block\n",
    "nb = multi_processor_count * 32     # number of blocks\n",
    "print(tpb)\n",
    "print(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpb2d = tpb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def transformv2(A:np.ndarray, b: np.ndarray, X: np.ndarray, Y: np.ndarray):\n",
    "    # tpb2d, _ = cuda.blockDim(2)\n",
    "\n",
    "    sX = cuda.shared.array(shape=(tpb2d,tpb2d), dtype=float64)\n",
    "    sA = cuda.shared.array(shape=(tpb2d,tpb2d), dtype=float64)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "    # stridex, stridey = cuda.gridsize(2)\n",
    "\n",
    "    tx, ty = cuda.threadIdx.x, cuda.threadIdx.y \n",
    "\n",
    "    bpg = cuda.gridDim.x    # blocks per grid, aka grid Dim\n",
    "\n",
    "    \n",
    "    # for i in range(idx,Y.shape[0],stridex):\n",
    "    #     for j in range(idy, Y.shape[1],stridey):\n",
    "    temp = float64(0.)\n",
    "    for i in range(bpg):\n",
    "        \n",
    "        # Preload chunks of data into shared memory\n",
    "        sX[tx,ty] = 0 \n",
    "        sA[tx,ty] = 0\n",
    "        if y < X.shape[0] and (tx + i * tpb2d) < X.shape[1]:\n",
    "            sX[ty,tx] = X[y,tx + i * tpb2d]\n",
    "        if x < A.shape[1] and (ty + i * tpb2d) < A.shape[0]:\n",
    "            sA[ty, tx] = A[ty + i * tpb2d, x]\n",
    "\n",
    "        # wait till loading complete\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Do partial row * col\n",
    "        for j in range(tpb2d):\n",
    "            temp += sX[ty, j] * sA[j, tx]\n",
    "\n",
    "        # Sync again\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    # Put result back in\n",
    "    if y < Y.shape[0] and x < Y.shape[1]:\n",
    "        Y[y,x] = temp + b[0,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Setup\n",
    "N = 20\n",
    "A = np.random.random((5,5)).astype(np.float32)\n",
    "X = np.random.random((N,5)).astype(np.float32)\n",
    "b = np.random.random((1,5)).astype(np.float32)\n",
    "Y = np.zeros_like(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "tpb2d_ = (tpb,tpb)\n",
    "# nb2d_ = (math.ceil(Y.shape[0]/tpb)(Y.s),math.cel)\n",
    "nb2d_ = (math.ceil(Y.shape[0] / tpb), math.ceil(Y.shape[1]/tpb))\n",
    "\n",
    "# Shared memory size\n",
    "# shared_mem_size = 2 * tpb * tpb * np.dtype(np.float64).itemsize\n",
    "\n",
    "print(tpb2d_)\n",
    "print(nb2d_)\n",
    "# print(shared_mem_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harris/miniconda3/envs/vmcmc/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "truth = X@A  + np.tile(b,(N,1))\n",
    "btruth = X@A + b\n",
    "\n",
    "# tranformsl(A,b,X,Y)\n",
    "dA = cuda.to_device(A)\n",
    "dX = cuda.to_device(X)\n",
    "db = cuda.to_device(b)\n",
    "dY = cuda.to_device(Y)\n",
    "# tranformv1[nb,tpb](dA,db,dX,dY)\n",
    "transformv2[nb2d_,tpb2d_](dA,db,dX,dY)\n",
    "Y = dY.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0000000e+00,  0.0000000e+00, -1.1920929e-07,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        -1.1920929e-07],\n",
       "       [ 5.9604645e-08, -1.1920929e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  1.1920929e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  1.1920929e-07, -1.1920929e-07,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  1.1920929e-07,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00, -1.1920929e-07, -1.1920929e-07,\n",
       "         5.9604645e-08],\n",
       "       [ 2.9802322e-08,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [-5.9604645e-08,  0.0000000e+00,  1.1920929e-07,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 1.1920929e-07,  0.0000000e+00, -1.1920929e-07,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 1.1920929e-07,  2.3841858e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [-5.9604645e-08,  0.0000000e+00,  0.0000000e+00,  2.3841858e-07,\n",
       "        -1.1920929e-07],\n",
       "       [ 1.1920929e-07,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [-5.9604645e-08,  0.0000000e+00,  0.0000000e+00,  2.3841858e-07,\n",
       "         0.0000000e+00],\n",
       "       [ 1.1920929e-07,  1.1920929e-07,  0.0000000e+00, -1.1920929e-07,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         5.9604645e-08],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y - truth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmcmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
