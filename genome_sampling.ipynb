{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsy\n",
    "from PolyRound.api import PolyRoundApi\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2025-11-24\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"hopsy\",\"examples\",\"test_data\", \"e_coli_core.xml\")\n",
    "polytope = PolyRoundApi.sbml_to_polytope(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rounding transformation took 3.874317241999961 seconds\n"
     ]
    }
   ],
   "source": [
    "problem = hopsy.Problem(polytope.A, polytope.b)\n",
    "problem = hopsy.add_box_constraints(problem, upper_bound=10_000, lower_bound=-10_000, simplify=True)\n",
    "start = time.perf_counter()\n",
    "problem = hopsy.round(problem)\n",
    "print(\"Computing rounding transformation took\", time.perf_counter()-start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 95)\n",
      "(190,)\n",
      "(190, 95)\n",
      "(190,)\n"
     ]
    }
   ],
   "source": [
    "print(polytope.A.shape)\n",
    "print(polytope.b.shape)\n",
    "print(problem.A.shape)\n",
    "print(problem.b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 511\n",
    "chains, rngs = hopsy.setup(problem, seed, n_chains=4)\n",
    "n_samples = 10000\n",
    "# Either use thinning rule, see  10.1371/journal.pcbi.1011378\n",
    "# or use one-shot transformation (for expert users). We show one-shot transformation at the end.\n",
    "thinning = int(1./6*problem.transformation.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Sampling with Transform <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling with internal trafo took 1.3233584550000614 seconds\n",
      "(4, 100000, 95)\n",
      "rhat: 1.0001632483672327\n",
      "ess: 15137.688482919848\n"
     ]
    }
   ],
   "source": [
    "%%script False\n",
    "start = time.perf_counter()\n",
    "accrate, samples = hopsy.sample(chains, rngs, n_samples, thinning=thinning, n_procs=4)\n",
    "# accrate is 1 for uniform samples with the default chains given by hopsy.setup()\n",
    "print(\"sampling with internal trafo took\", time.perf_counter()-start,\"seconds\")\n",
    "print(samples.shape)\n",
    "rhat = np.max(hopsy.rhat(samples))\n",
    "print(\"rhat:\", rhat)\n",
    "ess = np.min(hopsy.ess(samples)) / len(chains)\n",
    "print(\"ess:\", ess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sampling without Transform<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling took 1.3485633060000737 seconds\n",
      "sample shape (4, 100000, 95)\n",
      "rhat: 1.0001668563228547\n",
      "ess: 15199.932708453518\n"
     ]
    }
   ],
   "source": [
    "assert problem.transformation is not None\n",
    "# deep copy enures that we do not edit the original problem\n",
    "problem2 = copy.deepcopy(problem)\n",
    "problem2.transformation=None\n",
    "problem2.shift=None\n",
    "seed = 512\n",
    "chains, rngs = hopsy.setup(problem2, seed, n_chains=4)\n",
    "n_samples = 100_000\n",
    "# thinning is still advised when hard drive memory is limisted to not to store too many samples \n",
    "thinning = int(1./6*problem.A.shape[1])  \n",
    "\n",
    "start = time.perf_counter()\n",
    "accrate, sample_stack = hopsy.sample(chains, rngs, n_samples, thinning=thinning, n_procs=4)\n",
    "# accrate is 1 for uniform samples with the default chains given by hopsy.setup()\n",
    "print(\"sampling took\", time.perf_counter()-start,\"seconds\")\n",
    "\n",
    "print('sample shape', sample_stack.shape)\n",
    "rhat = np.max(hopsy.rhat(sample_stack))\n",
    "print(\"rhat:\", rhat)\n",
    "ess = np.min(hopsy.ess(sample_stack)) / len(chains)\n",
    "print(\"ess:\", ess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of sample_stack\n",
    "sample_stack_seq = sample_stack.copy()\n",
    "sample_stack_pl = sample_stack.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Transform Back: Sequential<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation took 0.09082596899997952 seconds\n",
      "sample stats are the same (save numerics) before and after the linear transformation:\n",
      "rhat: 1.0017171320252791\n",
      "ess: 1429.2896264045694\n"
     ]
    }
   ],
   "source": [
    "# transform samples back all at once\n",
    "shift_t = np.array([problem.shift]).T\n",
    "start_trafo = time.perf_counter()\n",
    "full_samples = np.zeros((len(chains), n_samples, sample_stack.shape[2]))\n",
    "for i in range(len(chains)):\n",
    "    full_samples[i] = (problem.transformation@sample_stack[i].T).T + np.tile(shift_t, (1, n_samples)).T\n",
    "    \n",
    "print(\"transformation took\", time.perf_counter()-start_trafo,\"seconds\")\n",
    "print('sample stats are the same (save numerics) before and after the linear transformation:')\n",
    "rhat = np.max(hopsy.rhat(full_samples))\n",
    "print(\"rhat:\", rhat)\n",
    "ess = np.min(hopsy.ess(full_samples)) / len(chains)\n",
    "print(\"ess:\", ess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Transform Back: Parallel<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "from numba import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# Device Properties to get execution config\n",
    "# Get the current device\n",
    "device = cuda.get_current_device()\n",
    "\n",
    "# Access device properties\n",
    "warp_size = device.WARP_SIZE\n",
    "multi_processor_count = device.MULTIPROCESSOR_COUNT\n",
    "\n",
    "print(warp_size)\n",
    "print(multi_processor_count)\n",
    "tpb = warp_size                     # threads per block\n",
    "nb = multi_processor_count * 32     # number of blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 1)\n",
      "(95, 100000)\n"
     ]
    }
   ],
   "source": [
    "print(shift_t.shape)\n",
    "print(np.tile(shift_t, (1, n_samples)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version needs A and b to be input as transposed.\n",
    "\"\"\"\n",
    "Perform Y = X.A + b\n",
    "X : (n_samples, A.shape[0]), n_samples is parallelised\n",
    "Y : same shape as X\n",
    "b : Row vector\n",
    "\"\"\"\n",
    "@cuda.jit\n",
    "def tranformv1(A:np.ndarray, b: np.ndarray, X: np.ndarray, Y: np.ndarray):\n",
    "    idx = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    for i in range(idx,X.shape[0],stride):\n",
    "        for j in range(A.shape[1]):\n",
    "            temp = 0\n",
    "            for k in range(A.shape[0]):\n",
    "                temp += X[i,k] * A[k,j]\n",
    "            Y[i,j] = temp + b[0,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Setup\n",
    "N = 20\n",
    "A = np.random.random((5,5)).astype(np.float32)\n",
    "X = np.random.random((N,5)).astype(np.float32)\n",
    "b = np.random.random((1,5)).astype(np.float32)\n",
    "Y = np.zeros_like(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = X@A + np.tile(b,(N,1))\n",
    "btruth = X@A + b\n",
    "\n",
    "# tranformsl(A,b,X,Y)\n",
    "dA = cuda.to_device(A)\n",
    "dX = cuda.to_device(X)\n",
    "db = cuda.to_device(b)\n",
    "dY = cuda.to_device(Y)\n",
    "tranformv1[nb,tpb](dA,db,dX,dY)\n",
    "Y = dY.copy_to_host()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0000000e+00, -1.1920929e-07,  0.0000000e+00, -1.1920929e-07,\n",
       "         0.0000000e+00],\n",
       "       [ 2.3841858e-07,  2.3841858e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "        -2.3841858e-07],\n",
       "       [ 0.0000000e+00, -1.1920929e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 2.3841858e-07, -2.3841858e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00, -2.3841858e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  2.3841858e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00, -1.1920929e-07,  0.0000000e+00, -1.1920929e-07,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.1920929e-07,\n",
       "         1.1920929e-07],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00, -1.1920929e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "        -1.1920929e-07],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [-2.3841858e-07,  0.0000000e+00,  2.3841858e-07,  1.1920929e-07,\n",
       "        -1.1920929e-07],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.1920929e-07,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  1.1920929e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00, -1.1920929e-07,  1.1920929e-07,\n",
       "         1.1920929e-07]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y - truth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
